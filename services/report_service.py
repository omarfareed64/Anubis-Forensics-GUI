import json
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.llms.together import TogetherLLM
from llama_index.core.node_parser import SimpleNodeParser
from llama_index.core.schema import Document
from pathlib import Path
from datetime import datetime
from random import randint
import os

class ReportService:
    def __init__(self, memory_analysis_dir="Anubis-Forensics-GUI/memory_analysis"):
        self.memory_analysis_dir = memory_analysis_dir
        self.llm = TogetherLLM(
            model="mistralai/Mistral-7B-Instruct-v0.1",
            api_key="3465dc5256bbade99b687fc318b9150cdae107e1a6af820e0e507926e32de42f"
        )
        self.embed_model = HuggingFaceEmbedding(model_name="all-MiniLM-L6-v2")
        Settings.llm = self.llm
        Settings.embed_model = self.embed_model

    def load_json_to_docs(self, folder):
        docs = []
        for file in Path(folder).glob("*.json"):
            with open(file, "r", encoding="utf-8") as f:
                data = json.load(f)
                content = json.dumps(data, indent=2)
                section = "unknown"
                if "malfind" in file.name:
                    section = "malfind"
                elif "pslist" in file.name:
                    section = "pslist"
                elif "filtered_netscan" in file.name:
                    section = "netscan"
                elif "virustotal" in file.name:
                    section = "virustotal"
                elif "dumped_memory_features" in file.name:
                    section = "memory"
                docs.append(Document(text=content, metadata={"filename": file.name, "section": section}))
        return docs

    def generate_report(self):
        documents = self.load_json_to_docs(self.memory_analysis_dir)
        parser = SimpleNodeParser.from_defaults(chunk_size=512, chunk_overlap=128)
        nodes = parser.get_nodes_from_documents(documents)
        index = VectorStoreIndex(nodes)
        case_id = f"DFIR-{randint(1000, 9999)}"
        today = datetime.today().strftime('%Y-%m-%d')
        query_engine = index.as_query_engine()

        # Section queries
        malfind_query = "Extract all suspicious processes from malfind.json. Look for PAGE_EXECUTE_READWRITE protection, MZ headers, or injected code indicators. List each suspicious process with PID, process name, and specific indicators found."
        pslist_query = "Extract process relationships from pslist.json. Focus on parent-child relationships and any processes that might be related to suspicious activities."
        netscan_query = "Extract suspicious network connections from filtered_netscan.json. Look for external IP connections, unusual ports, or connections to known malicious IPs."
        vt_query = "Extract malicious binary information from virustotal_results.json. List any files with positive detections, their hashes, and detection counts."

        try:
            malfind_response = query_engine.query(malfind_query)
        except Exception:
            malfind_response = "No malfind data retrieved"
        try:
            pslist_response = query_engine.query(pslist_query)
        except Exception:
            pslist_response = "No process list data retrieved"
        try:
            netscan_response = query_engine.query(netscan_query)
        except Exception:
            netscan_response = "No network scan data retrieved"
        try:
            vt_response = query_engine.query(vt_query)
        except Exception:
            vt_response = "No VirusTotal data retrieved"

        final_prompt = f'''
You are a digital forensics expert. Using the following extracted data from each section, generate a comprehensive Digital Forensics Memory Investigation Report.

SECTION DATA:
1. MALFIND ANALYSIS:
{malfind_response}

2. PROCESS RELATIONSHIPS:
{pslist_response}

3. NETWORK CONNECTIONS:
{netscan_response}

4. VIRUSTOTAL RESULTS:
{vt_response}

Generate the report in this exact format:

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ðŸ“„ Digital Forensics Memory Investigation Report  
Generated by: ChatGPT-4 (via Together API)  
Case ID: {case_id}  
Date: {today}  

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

1. Executive Summary  
Provide a concise summary of suspicious processes, malware detections, and key network threats based on the data above.

2. Suspicious Processes Overview  
List processes with memory injection indicators and their parent/child relationships.

| PID  | Process Name | Parent PID | Child PIDs | Memory Injection Indicators | Notes |
|------|--------------|------------|------------|-----------------------------|-------|

3. Malicious Binaries (VirusTotal Analysis)  

| File Name | Hash (SHA256) | Associated PID | VT Detections | Top Signatures |
|----------|----------------|----------------|----------------|----------------|

4. Network Indicators of Compromise  

| Remote IP | Port | Protocol | State | Connected PID | Process Name | Process Relationships |
|-----------|------|----------|-------|----------------|---------------|------------------------|

5. Process Relationship Graph Summary  
Summarize propagation/infection patterns using parent-child data and network links.

6. Extracted Indicators of Compromise (IOCs)  
List hashes, filenames, and IPs considered malicious or suspicious.

7. Analyst Recommendations  
Suggest actionable steps for containment and further analysis.

8. Appendix  
Include references to data files and memory sources used.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

IMPORTANT: 
- Use the exact data provided in each section above
- If a section has no data, state "No data available" rather than making up information
- Be specific about what was found in each analysis
- Format tables properly with actual data from the sections above
- Do not repeat the section headers in the response, just provide the content
- Start with the Executive Summary and provide a clear overview of findings
'''
        try:
            final_response = query_engine.query(final_prompt)
            return str(final_response)
        except Exception as e:
            return f"Report generation failed: {e}" 